{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Zenith Insurance ML Models - Model Registry\n",
        "\n",
        "This notebook trains ML models for the Zenith Insurance Intelligence Agent:\n",
        "- **Claim Cost Prediction** - Predict total incurred costs for claims\n",
        "- **Fraud Detection** - Classify claims as potential fraud risks\n",
        "- **Return-to-Work Timeline** - Predict days to return to work\n",
        "\n",
        "All models are registered to Snowflake Model Registry and can be added as tools to the Intelligence Agent.\n",
        "\n",
        "## Before You Begin\n",
        "\n",
        "**Add these packages** in the Packages dropdown (upper right):\n",
        "- `snowflake-ml-python`\n",
        "- `scikit-learn`\n",
        "- `xgboost`\n",
        "- `matplotlib`\n",
        "\n",
        "**Database:** ZENITH_INSURANCE_INTELLIGENCE  \n",
        "**Schema:** ANALYTICS  \n",
        "**Warehouse:** ZENITH_WH\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Import Required Packages\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import Python packages\n",
        "import pandas as pd\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Import Snowpark\n",
        "from snowflake.snowpark.context import get_active_session\n",
        "import snowflake.snowpark.functions as F\n",
        "import snowflake.snowpark.types as T\n",
        "from snowflake.snowpark import Window\n",
        "\n",
        "# Import Snowpark ML\n",
        "from snowflake.ml.modeling.preprocessing import StandardScaler, OneHotEncoder\n",
        "from snowflake.ml.modeling.pipeline import Pipeline\n",
        "from snowflake.ml.modeling.linear_model import LinearRegression, LogisticRegression\n",
        "from snowflake.ml.modeling.ensemble import RandomForestClassifier\n",
        "from snowflake.ml.modeling.metrics import mean_squared_error, mean_absolute_error, accuracy_score, roc_auc_score\n",
        "from snowflake.ml.registry import Registry\n",
        "\n",
        "print(\"✅ Packages imported successfully\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Connect to Snowflake\n",
        "\n",
        "Get active session and set context to Zenith Insurance database.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get active Snowflake session\n",
        "session = get_active_session()\n",
        "\n",
        "# Set context\n",
        "session.use_database('ZENITH_INSURANCE_INTELLIGENCE')\n",
        "session.use_schema('ANALYTICS')\n",
        "session.use_warehouse('ZENITH_WH')\n",
        "\n",
        "print(f\"✅ Connected - Role: {session.get_current_role()}\")\n",
        "print(f\"   Warehouse: {session.get_current_warehouse()}\")\n",
        "print(f\"   Database.Schema: {session.get_fully_qualified_current_schema()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# MODEL 1: Claim Cost Prediction\n",
        "\n",
        "Predict total incurred costs for claims based on injury characteristics.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Prepare Claim Cost Training Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get claim data with features\n",
        "claim_cost_df = session.sql(\"\"\"\n",
        "SELECT\n",
        "    c.claim_id,\n",
        "    c.injury_type,\n",
        "    c.body_part,\n",
        "    c.claim_type,\n",
        "    c.severity,\n",
        "    e.industry_vertical,\n",
        "    e.business_segment,\n",
        "    iw.age::FLOAT AS worker_age,\n",
        "    iw.years_of_experience::FLOAT AS worker_experience,\n",
        "    iw.safety_training_completed::BOOLEAN AS safety_trained,\n",
        "    c.days_lost::FLOAT AS days_lost,\n",
        "    c.total_incurred::FLOAT AS total_incurred\n",
        "FROM RAW.CLAIMS c\n",
        "JOIN RAW.EMPLOYERS e ON c.employer_id = e.employer_id\n",
        "LEFT JOIN RAW.INJURED_WORKERS iw ON c.injured_worker_id = iw.injured_worker_id\n",
        "WHERE c.claim_status = 'CLOSED'\n",
        "  AND c.total_incurred > 0\n",
        "  AND c.injury_date >= DATEADD('year', -3, CURRENT_DATE())\n",
        "\"\"\")\n",
        "\n",
        "print(f\"Claim cost data: {claim_cost_df.count()} closed claims\")\n",
        "claim_cost_df.show(5)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Train Claim Cost Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train/test split\n",
        "train_cost, test_cost = claim_cost_df.random_split([0.8, 0.2], seed=42)\n",
        "\n",
        "# Drop CLAIM_ID (VARCHAR not supported)\n",
        "train_cost = train_cost.drop(\"CLAIM_ID\")\n",
        "test_cost = test_cost.drop(\"CLAIM_ID\")\n",
        "\n",
        "# Create pipeline\n",
        "cost_pipeline = Pipeline([\n",
        "    (\"Encoder\", OneHotEncoder(\n",
        "        input_cols=[\"INJURY_TYPE\", \"BODY_PART\", \"CLAIM_TYPE\", \"SEVERITY\", \"INDUSTRY_VERTICAL\", \"BUSINESS_SEGMENT\"],\n",
        "        output_cols=[\"INJURY_TYPE_ENC\", \"BODY_PART_ENC\", \"CLAIM_TYPE_ENC\", \"SEVERITY_ENC\", \"INDUSTRY_ENC\", \"SEGMENT_ENC\"],\n",
        "        drop_input_cols=True,\n",
        "        handle_unknown=\"ignore\"\n",
        "    )),\n",
        "    (\"Scaler\", StandardScaler(\n",
        "        input_cols=[\"WORKER_AGE\", \"WORKER_EXPERIENCE\", \"DAYS_LOST\"],\n",
        "        output_cols=[\"WORKER_AGE_SCALED\", \"WORKER_EXPERIENCE_SCALED\", \"DAYS_LOST_SCALED\"]\n",
        "    )),\n",
        "    (\"Regressor\", LinearRegression(\n",
        "        label_cols=[\"TOTAL_INCURRED\"],\n",
        "        output_cols=[\"PREDICTED_COST\"]\n",
        "    ))\n",
        "])\n",
        "\n",
        "# Train model\n",
        "cost_pipeline.fit(train_cost)\n",
        "print(\"✅ Claim cost prediction model trained\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Evaluate and Register Claim Cost Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Make predictions on test set\n",
        "cost_predictions = cost_pipeline.predict(test_cost)\n",
        "\n",
        "# Calculate metrics\n",
        "mae = mean_absolute_error(df=cost_predictions, y_true_col_names=\"TOTAL_INCURRED\", y_pred_col_names=\"PREDICTED_COST\")\n",
        "mse = mean_squared_error(df=cost_predictions, y_true_col_names=\"TOTAL_INCURRED\", y_pred_col_names=\"PREDICTED_COST\")\n",
        "rmse = mse ** 0.5\n",
        "\n",
        "cost_metrics = {\"mae\": round(mae, 2), \"rmse\": round(rmse, 2)}\n",
        "print(f\"Claim cost model metrics: {cost_metrics}\")\n",
        "\n",
        "# Register model to Model Registry\n",
        "reg = Registry(session)\n",
        "reg.log_model(\n",
        "    model=cost_pipeline,\n",
        "    model_name=\"CLAIM_COST_PREDICTOR\",\n",
        "    version_name=\"V1\",\n",
        "    comment=\"Predicts total incurred claim costs using Linear Regression based on injury characteristics and worker demographics\",\n",
        "    metrics=cost_metrics\n",
        ")\n",
        "\n",
        "print(\"✅ Claim cost model registered to Model Registry as CLAIM_COST_PREDICTOR\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# MODEL 2: Fraud Detection\n",
        "\n",
        "Classify claims as potential fraud risks based on claim characteristics and patterns.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Prepare Fraud Detection Training Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get claim features for fraud detection\n",
        "fraud_df = session.sql(\"\"\"\n",
        "SELECT\n",
        "    c.claim_id,\n",
        "    c.injury_type,\n",
        "    c.body_part,\n",
        "    c.claim_type,\n",
        "    c.severity,\n",
        "    e.industry_vertical,\n",
        "    -- Days between injury and report (red flag if long delay)\n",
        "    DATEDIFF('day', c.injury_date, c.report_date)::FLOAT AS days_to_report,\n",
        "    c.litigated::BOOLEAN AS has_litigation,\n",
        "    iw.injury_history_count::FLOAT AS prior_injuries,\n",
        "    -- Cost ratio (high indemnity vs medical can indicate fraud)\n",
        "    CASE WHEN c.medical_paid > 0 \n",
        "         THEN (c.indemnity_paid / NULLIF(c.medical_paid, 0))::FLOAT \n",
        "         ELSE 0.0 END AS indemnity_medical_ratio,\n",
        "    -- Target: Has SIU investigation or dispute\n",
        "    (EXISTS (SELECT 1 FROM RAW.SIU_INVESTIGATION_REPORTS sir \n",
        "             WHERE sir.claim_id = c.claim_id \n",
        "             AND sir.investigation_status = 'CONFIRMED_FRAUD')\n",
        "     OR EXISTS (SELECT 1 FROM RAW.CLAIM_DISPUTES cd \n",
        "                WHERE cd.claim_id = c.claim_id \n",
        "                AND cd.dispute_type IN ('COMPENSABILITY', 'CAUSATION')))::BOOLEAN AS is_fraud_risk\n",
        "FROM RAW.CLAIMS c\n",
        "JOIN RAW.EMPLOYERS e ON c.employer_id = e.employer_id\n",
        "LEFT JOIN RAW.INJURED_WORKERS iw ON c.injured_worker_id = iw.injured_worker_id\n",
        "WHERE c.claim_status IN ('CLOSED', 'LITIGATED')\n",
        "  AND c.injury_date >= DATEADD('year', -3, CURRENT_DATE())\n",
        "\"\"\")\n",
        "\n",
        "print(f\"Fraud detection data: {fraud_df.count()} claims\")\n",
        "fraud_df.show(5)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Train Fraud Detection Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train/test split\n",
        "train_fraud, test_fraud = fraud_df.random_split([0.8, 0.2], seed=42)\n",
        "\n",
        "# Drop CLAIM_ID\n",
        "train_fraud = train_fraud.drop(\"CLAIM_ID\")\n",
        "test_fraud = test_fraud.drop(\"CLAIM_ID\")\n",
        "\n",
        "# Create pipeline\n",
        "fraud_pipeline = Pipeline([\n",
        "    (\"Encoder\", OneHotEncoder(\n",
        "        input_cols=[\"INJURY_TYPE\", \"BODY_PART\", \"CLAIM_TYPE\", \"SEVERITY\", \"INDUSTRY_VERTICAL\"],\n",
        "        output_cols=[\"INJURY_TYPE_ENC\", \"BODY_PART_ENC\", \"CLAIM_TYPE_ENC\", \"SEVERITY_ENC\", \"INDUSTRY_ENC\"],\n",
        "        drop_input_cols=True,\n",
        "        handle_unknown=\"ignore\"\n",
        "    )),\n",
        "    (\"Classifier\", RandomForestClassifier(\n",
        "        label_cols=[\"IS_FRAUD_RISK\"],\n",
        "        output_cols=[\"FRAUD_PREDICTION\"],\n",
        "        n_estimators=100,\n",
        "        max_depth=15\n",
        "    ))\n",
        "])\n",
        "\n",
        "# Train model\n",
        "fraud_pipeline.fit(train_fraud)\n",
        "print(\"✅ Fraud detection model trained\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Evaluate and Register Fraud Mo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Make predictions\n",
        "fraud_predictions = fraud_pipeline.predict(test_fraud)\n",
        "\n",
        "# Calculate metrics\n",
        "fraud_accuracy = accuracy_score(df=fraud_predictions, y_true_col_names=\"IS_FRAUD_RISK\", y_pred_col_names=\"FRAUD_PREDICTION\")\n",
        "fraud_metrics = {\"accuracy\": round(fraud_accuracy, 4)}\n",
        "print(f\"Fraud detection model metrics: {fraud_metrics}\")\n",
        "\n",
        "# Register model\n",
        "reg.log_model(\n",
        "    model=fraud_pipeline,\n",
        "    model_name=\"FRAUD_DETECTOR\",\n",
        "    version_name=\"V1\",\n",
        "    comment=\"Classifies claims as fraud risks using Random Forest based on claim patterns and anomalies\",\n",
        "    metrics=fraud_metrics\n",
        ")\n",
        "\n",
        "print(\"✅ Fraud detection model registered to Model Registry as FRAUD_DETECTOR\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# MODEL 3: Return-to-Work Timeline Prediction\n",
        "\n",
        "Predict number of days until injured worker returns to work.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Prepare Return-to-Work Training Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get return-to-work data\n",
        "rtw_df = session.sql(\"\"\"\n",
        "SELECT\n",
        "    c.claim_id,\n",
        "    c.injury_type,\n",
        "    c.body_part,\n",
        "    c.claim_type,\n",
        "    c.severity,\n",
        "    e.industry_vertical,\n",
        "    e.business_segment,\n",
        "    e.safety_rating,\n",
        "    iw.age::FLOAT AS worker_age,\n",
        "    iw.years_of_experience::FLOAT AS worker_experience,\n",
        "    iw.safety_training_completed::BOOLEAN AS safety_trained,\n",
        "    adj.adjuster_type,\n",
        "    -- Target: Days to return to work\n",
        "    DATEDIFF('day', c.injury_date, c.return_to_work_date)::FLOAT AS days_to_rtw\n",
        "FROM RAW.CLAIMS c\n",
        "JOIN RAW.EMPLOYERS e ON c.employer_id = e.employer_id\n",
        "LEFT JOIN RAW.INJURED_WORKERS iw ON c.injured_worker_id = iw.injured_worker_id\n",
        "LEFT JOIN RAW.CLAIMS_ADJUSTERS adj ON c.adjuster_id = adj.adjuster_id\n",
        "WHERE c.return_to_work_date IS NOT NULL\n",
        "  AND c.claim_status = 'CLOSED'\n",
        "  AND DATEDIFF('day', c.injury_date, c.return_to_work_date) BETWEEN 1 AND 365\n",
        "\"\"\")\n",
        "\n",
        "print(f\"Return-to-work data: {rtw_df.count()} claims with RTW\")\n",
        "rtw_df.show(5)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Train Return-to-Work Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train/test split\n",
        "train_rtw, test_rtw = rtw_df.random_split([0.8, 0.2], seed=42)\n",
        "\n",
        "# Drop CLAIM_ID\n",
        "train_rtw = train_rtw.drop(\"CLAIM_ID\")\n",
        "test_rtw = test_rtw.drop(\"CLAIM_ID\")\n",
        "\n",
        "# Create pipeline\n",
        "rtw_pipeline = Pipeline([\n",
        "    (\"Encoder\", OneHotEncoder(\n",
        "        input_cols=[\"INJURY_TYPE\", \"BODY_PART\", \"CLAIM_TYPE\", \"SEVERITY\", \n",
        "                   \"INDUSTRY_VERTICAL\", \"BUSINESS_SEGMENT\", \"SAFETY_RATING\", \"ADJUSTER_TYPE\"],\n",
        "        output_cols=[\"INJURY_TYPE_ENC\", \"BODY_PART_ENC\", \"CLAIM_TYPE_ENC\", \"SEVERITY_ENC\",\n",
        "                    \"INDUSTRY_ENC\", \"SEGMENT_ENC\", \"SAFETY_ENC\", \"ADJUSTER_ENC\"],\n",
        "        drop_input_cols=True,\n",
        "        handle_unknown=\"ignore\"\n",
        "    )),\n",
        "    (\"Scaler\", StandardScaler(\n",
        "        input_cols=[\"WORKER_AGE\", \"WORKER_EXPERIENCE\"],\n",
        "        output_cols=[\"WORKER_AGE_SCALED\", \"WORKER_EXPERIENCE_SCALED\"]\n",
        "    )),\n",
        "    (\"Regressor\", LinearRegression(\n",
        "        label_cols=[\"DAYS_TO_RTW\"],\n",
        "        output_cols=[\"PREDICTED_DAYS_TO_RTW\"]\n",
        "    ))\n",
        "])\n",
        "\n",
        "# Train\n",
        "rtw_pipeline.fit(train_rtw)\n",
        "print(\"✅ Return-to-work timeline model trained\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Evaluate and Register RTW Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Predict on test set\n",
        "rtw_predictions = rtw_pipeline.predict(test_rtw)\n",
        "\n",
        "# Calculate accuracy\n",
        "rtw_mae = mean_absolute_error(df=rtw_predictions, y_true_col_names=\"DAYS_TO_RTW\", y_pred_col_names=\"PREDICTED_DAYS_TO_RTW\")\n",
        "rtw_mse = mean_squared_error(df=rtw_predictions, y_true_col_names=\"DAYS_TO_RTW\", y_pred_col_names=\"PREDICTED_DAYS_TO_RTW\")\n",
        "rtw_rmse = rtw_mse ** 0.5\n",
        "\n",
        "rtw_metrics = {\"mae\": round(rtw_mae, 2), \"rmse\": round(rtw_rmse, 2)}\n",
        "print(f\"Return-to-work model metrics: {rtw_metrics}\")\n",
        "\n",
        "# Register model\n",
        "reg.log_model(\n",
        "    model=rtw_pipeline,\n",
        "    model_name=\"RTW_TIMELINE_PREDICTOR\",\n",
        "    version_name=\"V1\",\n",
        "    comment=\"Predicts days to return to work using Linear Regression based on injury and worker characteristics\",\n",
        "    metrics=rtw_metrics\n",
        ")\n",
        "\n",
        "print(\"✅ RTW timeline model registered to Model Registry as RTW_TIMELINE_PREDICTOR\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# Verify Models in Registry\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Show all models in the registry\n",
        "print(\"Models in registry:\")\n",
        "reg.show_models()\n",
        "\n",
        "# Show versions for each model\n",
        "print(\"\\nClaim cost model versions:\")\n",
        "reg.get_model(\"CLAIM_COST_PREDICTOR\").show_versions()\n",
        "\n",
        "print(\"\\nFraud detector versions:\")\n",
        "reg.get_model(\"FRAUD_DETECTOR\").show_versions()\n",
        "\n",
        "print(\"\\nRTW timeline predictor versions:\")\n",
        "reg.get_model(\"RTW_TIMELINE_PREDICTOR\").show_versions()\n",
        "\n",
        "print(\"\\n✅ All models registered and ready to add to Intelligence Agent\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# Test Model Inference\n",
        "\n",
        "Test calling each model to make predictions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test claim cost prediction\n",
        "cost_model = reg.get_model(\"CLAIM_COST_PREDICTOR\").default\n",
        "sample_claims = claim_cost_df.limit(5).drop(\"CLAIM_ID\")\n",
        "cost_preds = cost_model.run(sample_claims, function_name=\"predict\")\n",
        "print(\"Claim cost predictions:\")\n",
        "cost_preds.select(\"INJURY_TYPE\", \"BODY_PART\", \"TOTAL_INCURRED\", \"PREDICTED_COST\").show()\n",
        "\n",
        "# Test fraud detection\n",
        "fraud_model = reg.get_model(\"FRAUD_DETECTOR\").default\n",
        "sample_fraud = fraud_df.limit(5).drop(\"CLAIM_ID\")\n",
        "fraud_preds = fraud_model.run(sample_fraud, function_name=\"predict\")\n",
        "print(\"\\nFraud risk predictions:\")\n",
        "fraud_preds.select(\"INJURY_TYPE\", \"DAYS_TO_REPORT\", \"IS_FRAUD_RISK\", \"FRAUD_PREDICTION\").show()\n",
        "\n",
        "# Test return-to-work prediction\n",
        "rtw_model = reg.get_model(\"RTW_TIMELINE_PREDICTOR\").default\n",
        "sample_rtw = rtw_df.limit(5).drop(\"CLAIM_ID\")\n",
        "rtw_preds = rtw_model.run(sample_rtw, function_name=\"predict\")\n",
        "print(\"\\nReturn-to-work timeline predictions:\")\n",
        "rtw_preds.select(\"INJURY_TYPE\", \"BODY_PART\", \"DAYS_TO_RTW\", \"PREDICTED_DAYS_TO_RTW\").show()\n",
        "\n",
        "print(\"\\n✅ All models tested successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# Next Steps\n",
        "\n",
        "## Add Models to Intelligence Agent\n",
        "\n",
        "1. Execute the wrapper procedures: `sql/ml/07_create_model_wrapper_functions.sql`\n",
        "2. In Snowsight → AI & ML → Agents → ZENITH_INSURANCE_INTELLIGENCE_AGENT\n",
        "3. Go to Tools → + Add → Procedure\n",
        "4. Add each procedure:\n",
        "   - **PREDICT_CLAIM_COST**\n",
        "   - **DETECT_FRAUD_RISK**\n",
        "   - **PREDICT_RTW_TIMELINE**\n",
        "\n",
        "## Example Questions for Agent\n",
        "\n",
        "- \"Predict claim costs for open back injury claims\"\n",
        "- \"Which open claims have high fraud risk according to the fraud detector?\"\n",
        "- \"Predict return-to-work timeline for shoulder injuries in healthcare\"\n",
        "\n",
        "The models will now be available as tools your agent can use!\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
